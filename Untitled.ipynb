{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_convertor import * #(f, w, bits)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil, log2\n",
    "from functools import reduce\n",
    "import operator\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_i_k(i, k, maximum_output):\n",
    "    this_image = i.copy()\n",
    "    this_kernel = k.copy()\n",
    "    all_max = max(this_image.max(), this_kernel.max())\n",
    "    mult_factor = (maximum_output / all_max)\n",
    "    this_image = this_image * mult_factor\n",
    "    this_image = this_image.astype(int)\n",
    "    this_kernel = this_kernel * mult_factor\n",
    "    this_kernel = this_kernel.astype(int)\n",
    "    return this_image, this_kernel, mult_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_egcd(a, b):\n",
    "    x,y, u,v = 0,1, 1,0\n",
    "    while a != 0:\n",
    "        q,r = b//a,b%a; m,n = x-u*q,y-v*q # use x//y for floor \"floor division\"\n",
    "        b,a, x,y, u,v = a,r, u,v, m,n\n",
    "    return b, x, y\n",
    "def modinv(a, m):\n",
    "    g, x, y = iterative_egcd(a, m) \n",
    "    if g != 1:\n",
    "        return None\n",
    "    else:\n",
    "        return x % m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_theorem(inputs, shape, upper_limit, peymane):\n",
    "    flat_inputs = list()\n",
    "    for i in inputs:\n",
    "        flat_inputs.append(i.flatten())\n",
    "    result = np.zeros(flat_inputs[0].shape)\n",
    "    B = list()\n",
    "    x = list()\n",
    "    for p in peymane:\n",
    "        peymanes_copy = peymane.copy()\n",
    "        peymanes_copy.remove(p)\n",
    "        B.append(functools.reduce(operator.mul, peymanes_copy, 1))\n",
    "        x.append(modinv(B[-1], p))\n",
    "    for i in range(len(flat_inputs[0])):\n",
    "        this_result = 0\n",
    "        for j in range(len(peymane)):\n",
    "            this_result += B[j] * x[j] * flat_inputs[j][i]\n",
    "        peymane_mult = functools.reduce(operator.mul, peymane, 1)\n",
    "        while(this_result > upper_limit):\n",
    "            this_result -= peymane_mult\n",
    "        result[i] = this_result\n",
    "    result = np.reshape(result, shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_np_quan_conv(a, b, stride, padding, max_range):\n",
    "    a_max = a.max()\n",
    "    b_max = b.max()\n",
    "    both_max = max([a_max, b_max])\n",
    "    a_quan = ((a * (max_range / both_max)).astype(int)).astype(float)\n",
    "    b_quan = ((b * (max_range / both_max)).astype(int)).astype(float)\n",
    "    conv = allah_conv(a_quan, b_quan, stride, padding)\n",
    "    conv_dequan = conv * ((both_max / max_range)**2)\n",
    "    \n",
    "    return conv_dequan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tensor_quan_conv(a, b, stride, padding, max_range):\n",
    "    a_max = tf.reduce_max(a)\n",
    "    b_max = tf.reduce_max(b)\n",
    "    max_concat = tf.stack([a_max, b_max])\n",
    "    both_max = tf.reduce_max(max_concat)\n",
    "    a_muled = tf.multiply(a, max_range / both_max)\n",
    "    b_muled = tf.multiply(b, max_range / both_max)\n",
    "    a_quan = tf.cast(a_muled, tf.int32)\n",
    "    b_quan = tf.cast(b_muled, tf.int32)\n",
    "    float_a_quan = tf.cast(a_quan, tf.float32)\n",
    "    float_b_quan = tf.cast(b_quan, tf.float32)\n",
    "    conv = tf.nn.conv2d(float_a_quan, float_b_quan, stride, padding=padding)    \n",
    "    conv_dequan_one = tf.multiply(conv, both_max / max_range)\n",
    "    conv_dequan = tf.multiply(conv_dequan_one, both_max / max_range)\n",
    "    \n",
    "    return conv_dequan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_conv(image, kernel, s_h, s_w, padding):\n",
    "    image_min = tf.reduce_min(image)\n",
    "    image_max = tf.reduce_max(image)\n",
    "    kernel_min = tf.reduce_min(kernel)\n",
    "    kernel_max = tf.reduce_max(kernel)\n",
    "    quantized_image, _,_ = tf.quantize(image, image_min, image_max, tf.quint8)\n",
    "    quantized_kernel, _, _= tf.quantize(kernel, kernel_min, kernel_max, tf.quint8)\n",
    "    quan_conv = tf.nn.quantized_conv2d(quantized_image, quantized_kernel, image_min, image_max, \n",
    "                                   kernel_min, kernel_max, [1, s_h, s_w, 1], padding)\n",
    "    shit = tf.cast(quan_conv.output, dtype=tf.qint32)\n",
    "    deq_out = tf.quantization.dequantize(shit, quan_conv.min_output, quan_conv.max_output)\n",
    "    return deq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pad(arr, pad_top, pad_bottom, pad_left, pad_right):\n",
    "    pads = [pad_top, pad_bottom, pad_left, pad_right]\n",
    "    if(len(arr.shape) != 2 or arr.shape[0] != arr.shape[1]):\n",
    "        return arr\n",
    "    result = list()\n",
    "    for i in range(pads[0]):\n",
    "        result.append(np.zeros(arr.shape[0] + pads[2] + pads[3]))\n",
    "    for row in arr:\n",
    "        new_row = np.concatenate((np.zeros(pads[2]),row,np.zeros(pads[3])))\n",
    "        result.append(new_row)\n",
    "    for i in range(pads[1]):\n",
    "        result.append(np.zeros(arr.shape[0] + pads[2] + pads[3]))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allah_conv(inputs, filters, strides, padding, return_tf=False, use_skippy=False, bits=8): #(NHWC for image and HWCN for kernel)\n",
    "    with tf.Session() as sess:\n",
    "        if(type(inputs) != np.ndarray):\n",
    "            inputs = sess.run(inputs)\n",
    "        if(type(filters) != np.ndarray):\n",
    "            filters = sess.run(filters)\n",
    "    if(padding == \"VALID\"):\n",
    "        output_shape = (inputs.shape[0], ceil((inputs.shape[1] - filters.shape[0] + 1) / strides[1]), ceil((inputs.shape[2] - filters.shape[1] + 1) / strides[2]), filters.shape[3])\n",
    "    else: # SAME\n",
    "        if (inputs.shape[1] % strides[1] == 0):\n",
    "            pad_along_height = max(filters.shape[0] - strides[1], 0)\n",
    "        else:\n",
    "            pad_along_height = max(filters.shape[0] - (inputs.shape[1] % strides[1]), 0)\n",
    "        if (inputs.shape[2] % strides[2] == 0):\n",
    "            pad_along_width = max(filters.shape[1] - strides[2], 0)\n",
    "        else:\n",
    "            pad_along_width = max(filters.shape[1] - (inputs.shape[2] % strides[2]), 0)\n",
    "        pad_top = pad_along_height // 2\n",
    "        pad_bottom = pad_along_height - pad_top\n",
    "        pad_left = pad_along_width // 2\n",
    "        pad_right = pad_along_width - pad_left\n",
    "        trans_inputs = inputs.transpose((0, 3, 1, 2))\n",
    "        results = list()\n",
    "        for i in range(trans_inputs.shape[0]):\n",
    "            for j in range(trans_inputs.shape[1]):\n",
    "                results.append(my_pad(trans_inputs[i][j], pad_top, pad_bottom, pad_left, pad_right))\n",
    "        trans_inputs = np.zeros((trans_inputs.shape[0], trans_inputs.shape[1], results[0].shape[0], results[0].shape[1]))\n",
    "        for i in range(trans_inputs.shape[0]):\n",
    "            for j in range(trans_inputs.shape[1]):\n",
    "                trans_inputs[i][j] = results[i + j]\n",
    "        untrans_inputs = trans_inputs.transpose((0, 2, 3, 1))\n",
    "        output_shape = (int(inputs.shape[0]), int(ceil((inputs.shape[1]) / strides[1])), int(ceil((inputs.shape[2]) / strides[2])), int(filters.shape[3]))\n",
    "        inputs = untrans_inputs\n",
    "#     print(output_shape)\n",
    "    output = np.zeros(output_shape)\n",
    "#     print(output_shape[0]*output_shape[3] * output_shape[1] * output_shape[2] * filters.shape[1] * filters.shape[0] * inputs.shape[3])\n",
    "    for n_image in range(output_shape[0]):\n",
    "        for n_kernel in range(output_shape[3]):\n",
    "            for h_base in range(output_shape[1]):\n",
    "                for w_base in range(output_shape[2]):\n",
    "                    for h in range(filters.shape[0]):\n",
    "                        for w in range(filters.shape[1]):\n",
    "                            for c in range(inputs.shape[3]):\n",
    "                                this_input = inputs[n_image][h_base * strides[1] + h][w_base * strides[2] + w][c]\n",
    "                                this_filter = filters[h][w][c][n_kernel]\n",
    "                                if(use_skippy):\n",
    "                                    this_mult = sc_convertor.new_mult(this_input, this_filter, bits)\n",
    "#                                     this_mult = 0\n",
    "                                else:\n",
    "                                    this_mult = this_filter * this_input\n",
    "                                output[n_image][h_base][w_base][n_kernel] += this_mult\n",
    "    if return_tf:\n",
    "        return tf.constant(output, dtype=tf.float32, name=\"allah\")\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = [1, 1, 1, 1]\n",
    "channels = 3\n",
    "input_shape = (8,8)\n",
    "filter_shape = (3, 3)\n",
    "high = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = np.random.randint(size = (1, input_shape[0], input_shape[1], channels), low = 0, high = 5)\n",
    "nk = np.random.uniform(size = (filter_shape[0], filter_shape[1], channels, 1), low=0, high=1)\n",
    "k = tf.constant(nk, dtype=tf.float32)\n",
    "i = tf.constant(ni, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.nn.conv2d(i, k, stride, \"VALID\")\n",
    "# g = allah_conv(ni, nk, stride, \"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rns_conv(modulos, a, b, stride, padding, max_range, hight_range, use_new_mult = False):\n",
    "    a, b, mult_factor = quantize_i_k(a, b, hight_range)\n",
    "    normal_conv = allah_conv(a, b, stride, padding).astype(int)\n",
    "\n",
    "    new_a = [a % m for m in modulos]\n",
    "    new_b = [b % m for m in modulos]\n",
    "    conv_result = [allah_conv(new_a[i], new_b[i], stride, padding, use_skippy=use_new_mult, bits=ceil(log2(modulos[i]))) % modulos[i] for i in range(len(modulos))]\n",
    "    # convert back to binary\n",
    "    if(functools.reduce(operator.mul, modulos, 1) < (len(range(int(normal_conv.min()), int(normal_conv.max()))))):\n",
    "        print(\"Overflow\")\n",
    "        \n",
    "    demod_result = chinese_theorem(conv_result, normal_conv.shape, normal_conv.max(), modulos)\n",
    "    \n",
    "    dequan_result = demod_result / (mult_factor ** 2)\n",
    "    \n",
    "    return dequan_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = my_tensor_quan_conv(i, k, stride, \"VALID\", high)\n",
    "e = my_np_quan_conv(ni, nk, stride, \"VALID\", high)\n",
    "modulos = [7,8,9]\n",
    "f = rns_conv(modulos, ni, nk, stride, \"VALID\", high, 20, use_new_mult=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.20713\n",
      "34.20608000000001\n",
      "27.2\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(c).flatten()[10])\n",
    "#     print(g.flatten()[10])\n",
    "#     print(sess.run(d).flatten()[10])\n",
    "    print(e.flatten()[10])\n",
    "    print(f.flatten()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
