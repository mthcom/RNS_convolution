{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc_convertor import * #(f, w, bits)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_np_quan_conv(a, b, stride, padding, max_range):\n",
    "    a_max = a.max()\n",
    "    b_max = b.max()\n",
    "    both_max = max([a_max, b_max])\n",
    "    a_quan = ((a * (max_range / both_max)).astype(int)).astype(float)\n",
    "    b_quan = ((b * (max_range / both_max)).astype(int)).astype(float)\n",
    "    print(a_quan.flatten()[0], b_quan.flatten()[0])\n",
    "    conv = allah_conv(a_quan, b_quan, stride, padding)\n",
    "    conv_dequan = conv * ((both_max / max_range)**2)\n",
    "    \n",
    "    return conv_dequan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tensor_quan_conv(a, b, stride, padding, max_range):\n",
    "    a_max = tf.reduce_max(a)\n",
    "    b_max = tf.reduce_max(b)\n",
    "    max_concat = tf.stack([a_max, b_max])\n",
    "    both_max = tf.reduce_max(max_concat)\n",
    "    a_muled = tf.multiply(a, max_range / both_max)\n",
    "    b_muled = tf.multiply(b, max_range / both_max)\n",
    "    a_quan = tf.cast(a_muled, tf.int32)\n",
    "    b_quan = tf.cast(b_muled, tf.int32)\n",
    "    float_a_quan = tf.cast(a_quan, tf.float32)\n",
    "    float_b_quan = tf.cast(b_quan, tf.float32)\n",
    "    conv = tf.nn.conv2d(float_a_quan, float_b_quan, stride, padding=padding)    \n",
    "    conv_dequan_one = tf.multiply(conv, both_max / max_range)\n",
    "    conv_dequan = tf.multiply(conv_dequan_one, both_max / max_range)\n",
    "    \n",
    "    return conv_dequan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_conv(image, kernel, s_h, s_w, padding):\n",
    "    image_min = tf.reduce_min(image)\n",
    "    image_max = tf.reduce_max(image)\n",
    "    kernel_min = tf.reduce_min(kernel)\n",
    "    kernel_max = tf.reduce_max(kernel)\n",
    "    quantized_image, _,_ = tf.quantize(image, image_min, image_max, tf.quint8)\n",
    "    quantized_kernel, _, _= tf.quantize(kernel, kernel_min, kernel_max, tf.quint8)\n",
    "    quan_conv = tf.nn.quantized_conv2d(quantized_image, quantized_kernel, image_min, image_max, \n",
    "                                   kernel_min, kernel_max, [1, s_h, s_w, 1], padding)\n",
    "    shit = tf.cast(quan_conv.output, dtype=tf.qint32)\n",
    "    deq_out = tf.quantization.dequantize(shit, quan_conv.min_output, quan_conv.max_output)\n",
    "    return deq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pad(arr, pad_top, pad_bottom, pad_left, pad_right):\n",
    "    pads = [pad_top, pad_bottom, pad_left, pad_right]\n",
    "    if(len(arr.shape) != 2 or arr.shape[0] != arr.shape[1]):\n",
    "        return arr\n",
    "    result = list()\n",
    "    for i in range(pads[0]):\n",
    "        result.append(np.zeros(arr.shape[0] + pads[2] + pads[3]))\n",
    "    for row in arr:\n",
    "        new_row = np.concatenate((np.zeros(pads[2]),row,np.zeros(pads[3])))\n",
    "        result.append(new_row)\n",
    "    for i in range(pads[1]):\n",
    "        result.append(np.zeros(arr.shape[0] + pads[2] + pads[3]))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allah_conv(inputs, filters, strides, padding, return_tf=False, use_skippy=False, bits=8): #(NHWC for image and HWCN for kernel)\n",
    "    with tf.Session() as sess:\n",
    "        if(type(inputs) != np.ndarray):\n",
    "            inputs = sess.run(inputs)\n",
    "        if(type(filters) != np.ndarray):\n",
    "            filters = sess.run(filters)\n",
    "    if(padding == \"VALID\"):\n",
    "        output_shape = (inputs.shape[0], ceil((inputs.shape[1] - filters.shape[0] + 1) / strides[1]), ceil((inputs.shape[2] - filters.shape[1] + 1) / strides[2]), filters.shape[3])\n",
    "    else: # SAME\n",
    "        if (inputs.shape[1] % strides[1] == 0):\n",
    "            pad_along_height = max(filters.shape[0] - strides[1], 0)\n",
    "        else:\n",
    "            pad_along_height = max(filters.shape[0] - (inputs.shape[1] % strides[1]), 0)\n",
    "        if (inputs.shape[2] % strides[2] == 0):\n",
    "            pad_along_width = max(filters.shape[1] - strides[2], 0)\n",
    "        else:\n",
    "            pad_along_width = max(filters.shape[1] - (inputs.shape[2] % strides[2]), 0)\n",
    "        pad_top = pad_along_height // 2\n",
    "        pad_bottom = pad_along_height - pad_top\n",
    "        pad_left = pad_along_width // 2\n",
    "        pad_right = pad_along_width - pad_left\n",
    "        trans_inputs = inputs.transpose((0, 3, 1, 2))\n",
    "        results = list()\n",
    "        for i in range(trans_inputs.shape[0]):\n",
    "            for j in range(trans_inputs.shape[1]):\n",
    "                results.append(my_pad(trans_inputs[i][j], pad_top, pad_bottom, pad_left, pad_right))\n",
    "        trans_inputs = np.zeros((trans_inputs.shape[0], trans_inputs.shape[1], results[0].shape[0], results[0].shape[1]))\n",
    "        for i in range(trans_inputs.shape[0]):\n",
    "            for j in range(trans_inputs.shape[1]):\n",
    "                trans_inputs[i][j] = results[i + j]\n",
    "        untrans_inputs = trans_inputs.transpose((0, 2, 3, 1))\n",
    "        output_shape = (int(inputs.shape[0]), int(ceil((inputs.shape[1]) / strides[1])), int(ceil((inputs.shape[2]) / strides[2])), int(filters.shape[3]))\n",
    "        inputs = untrans_inputs\n",
    "#     print(output_shape)\n",
    "    output = np.zeros(output_shape)\n",
    "#     print(output_shape[0]*output_shape[3] * output_shape[1] * output_shape[2] * filters.shape[1] * filters.shape[0] * inputs.shape[3])\n",
    "    for n_image in range(output_shape[0]):\n",
    "        for n_kernel in range(output_shape[3]):\n",
    "            for h_base in range(output_shape[1]):\n",
    "                for w_base in range(output_shape[2]):\n",
    "                    for h in range(filters.shape[0]):\n",
    "                        for w in range(filters.shape[1]):\n",
    "                            for c in range(inputs.shape[3]):\n",
    "                                this_input = inputs[n_image][h_base * strides[1] + h][w_base * strides[2] + w][c]\n",
    "                                this_filter = filters[h][w][c][n_kernel]\n",
    "                                if(use_skippy):\n",
    "                                    this_mult = skippy_mult(int(this_input), this_filter, bits)\n",
    "                                else:\n",
    "                                    this_mult = this_filter * this_input\n",
    "                                output[n_image][h_base][w_base][n_kernel] += this_mult\n",
    "    if return_tf:\n",
    "        return tf.constant(output, dtype=tf.float32, name=\"allah\")\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = [1, 1, 1, 1]\n",
    "channels = 3\n",
    "input_shape = (8,8)\n",
    "filter_shape = (3, 3)\n",
    "high = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = np.random.randint(size = (1, input_shape[0], input_shape[1], channels), low = 0, high = 60)\n",
    "nk = np.random.uniform(size = (filter_shape[0], filter_shape[1], channels, 1), low=0, high=1)\n",
    "k = tf.constant(nk, dtype=tf.float32)\n",
    "i = tf.constant(ni, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.nn.conv2d(i, k, stride, \"VALID\")\n",
    "g = allah_conv(ni, nk, stride, \"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = my_tensor_quan_conv(i, k, stride, \"VALID\", high)\n",
    "e = my_np_quan_conv(ni, nk, stride, \"VALID\", high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(c).flatten()[10])\n",
    "#     print(g.flatten()[10])\n",
    "#     print(sess.run(d).flatten()[10])\n",
    "    print(e.flatten()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
